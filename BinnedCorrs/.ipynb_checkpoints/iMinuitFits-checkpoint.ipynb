{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b0f097-c548-41f6-a5ad-3935372624e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import UnbinnedNLL\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916932a1-b8ac-4f04-9b02-d55a5c20182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PARAMETERS'\n",
    "data_size = 10**4\n",
    "sim_size = 10**5\n",
    "n_iterations = 5\n",
    "n_bootstraps = 500\n",
    "epsilon = 1e-8\n",
    "rcond = 1e-3\n",
    "\n",
    "smearing = 1e-5\n",
    "\n",
    "mu_true, var_true = 0.2, 0.81\n",
    "mu_gen, var_gen = 0.0, 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9e223c-b441-4ce5-a564-937d30a3a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "'FUNCTIONS'\n",
    "normalize = lambda x: x / np.sum(x, axis=0) if np.sum(x, axis=0) != 0 else 0\n",
    "\n",
    "def create_response_matrix(gen, sim, bins):\n",
    "    H, _, _ = np.histogram2d(gen.ravel(), sim.ravel(), bins=[bins, bins])\n",
    "    H = normalize(H)\n",
    "    H[np.isnan(H)] = 0\n",
    "    return H\n",
    "\n",
    "def bayesian_unfolding_step(R, f, data_hist):\n",
    "    reweight = data_hist / (R @ f + epsilon)\n",
    "    reweight[np.isnan(reweight)] = 0\n",
    "    reweight[(R @ f) == 0] = 0\n",
    "    f_prime = f * (R @ reweight)\n",
    "    return normalize(f_prime)\n",
    "\n",
    "def iterative_bayesian_unfolding(data, gen, sim, bins, n_iterations):\n",
    "    fs = np.empty((n_iterations, len(bins) - 1, ))\n",
    "    R = create_response_matrix(gen, sim, bins)\n",
    "    f, _ = np.histogram(gen, bins=bins)\n",
    "    f = normalize(f)\n",
    "    data_hist, _ = np.histogram(data, bins=bins)\n",
    "    data_hist = normalize(data_hist)\n",
    "    sim_hist, _ = np.histogram(sim, bins=bins)\n",
    "    sim_hist = normalize(sim_hist)\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        f = bayesian_unfolding_step(R, f, data_hist)\n",
    "        fs[i] = f\n",
    "    return fs\n",
    "\n",
    "def cost(x, mu, var):\n",
    "    cdf_values = norm.cdf(x, mu, np.sqrt(var))\n",
    "    y_model = np.diff(cdf_values)\n",
    "    return y_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972af332-6134-4221-bb79-2060d0824668",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed = 5048)\n",
    "truth = rng.normal(mu_true, np.sqrt(var_true), (n_bootstraps, data_size))\n",
    "gen = rng.normal(mu_gen, np.sqrt(var_gen), (n_bootstraps, sim_size))\n",
    "\n",
    "data = rng.normal(truth, smearing)\n",
    "sim = rng.normal(gen, smearing)\n",
    "\n",
    "'BINS'\n",
    "bins = [truth.min()]\n",
    "i = 0\n",
    "while bins[-1] < truth.max() and i < len(bins):\n",
    "    for binhigh in np.linspace(bins[i] + epsilon, truth.max(), 20):\n",
    "        in_bin = (truth[0] > bins[i]) & (truth[0] < binhigh)\n",
    "        in_reco_bin = (data[0] > bins[i]) & (data[0] < binhigh)\n",
    "        if np.sum(in_bin) > 0:\n",
    "            purity = np.sum(in_bin & in_reco_bin) / np.sum(in_bin)\n",
    "            if purity > (0.5):\n",
    "                i += 1\n",
    "                bins.append(binhigh)\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "bins.append(truth.max())\n",
    "\n",
    "bins = np.array(bins)\n",
    "bin_widths = np.diff(bins)\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "n_bins = len(bins) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa63966-f059-4113-a75c-46b9a856da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "'IMPLEMENTATION'\n",
    "unfolded_results = np.empty((n_bootstraps, n_iterations, n_bins))\n",
    "for i in range(n_bootstraps):\n",
    "    unfolded_results[i] = iterative_bayesian_unfolding(data[i], gen[i], sim[i], bins, n_iterations)\n",
    "unfolded_results_last = unfolded_results[:, -1]\n",
    "\n",
    "cov = np.cov(unfolded_results_last.T)\n",
    "cov_diag = np.diag(np.diag(cov))\n",
    "\n",
    "    fitted_params = np.empty((n_bootstraps, 2))\n",
    "    intervals = np.empty((n_bootstraps, 2, 2))\n",
    "    intervals_diag = np.empty((n_bootstraps, 2, 2))\n",
    "    fitted_params_diag = np.empty((n_bootstraps, 2))\n",
    "    \n",
    "    bounds = [(-1, 1), (epsilon, 2)]\n",
    "    for i in range(n_bootstraps):\n",
    "        initial_guess = np.random.normal(0.5, 0.1, 2)\n",
    "        result = minimize(neg_log_likelihood,\n",
    "                          initial_guess,\n",
    "                          args=(bins, unfolded_results_last[i], cov),\n",
    "                          bounds=bounds)\n",
    "    \n",
    "        nll_min = result.fun  # Minimum NLL value\n",
    "        fitted_params[i] = result.x\n",
    "        intervals[i, 0] = find_confidence_interval(neg_log_likelihood,\n",
    "                                               0, result.x,\n",
    "                                               nll_min,\n",
    "                                               bins,\n",
    "                                               unfolded_results_last[i],\n",
    "                                               cov,\n",
    "                                               bounds)\n",
    "        intervals[i, 1] = find_confidence_interval(neg_log_likelihood,\n",
    "                                                  1,\n",
    "                                                  result.x,\n",
    "                                                  nll_min,\n",
    "                                                  bins,\n",
    "                                                  unfolded_results_last[i],\n",
    "                                                  cov,\n",
    "                                                  bounds)\n",
    "    \n",
    "        result_diag = minimize(neg_log_likelihood,\n",
    "                               initial_guess,\n",
    "                               args=(bins, unfolded_results_last[i], cov_diag),\n",
    "                               #method='L-BFGS-B',\n",
    "                               bounds = bounds\n",
    "                              )\n",
    "        nll_min_diag = result_diag.fun  # Minimum NLL value\n",
    "        fitted_params_diag[i] = result_diag.x\n",
    "        intervals_diag[i, 0] = find_confidence_interval(neg_log_likelihood,\n",
    "                                               0, result_diag.x,\n",
    "                                               nll_min_diag,\n",
    "                                               bins,\n",
    "                                               unfolded_results_last[i],\n",
    "                                               cov_diag,\n",
    "                                               bounds)\n",
    "        intervals_diag[i, 1] = find_confidence_interval(neg_log_likelihood,\n",
    "                                                  1,\n",
    "                                                  result_diag.x,\n",
    "                                                  nll_min_diag,\n",
    "                                                  bins,\n",
    "                                                  unfolded_results_last[i],\n",
    "                                                  cov_diag,\n",
    "                                                  bounds)\n",
    "    return {\n",
    "        \"full_cov\": {\n",
    "            \"mu\": np.mean(fitted_params[:, 0]),\n",
    "            \"sigma_on_mu\": np.std(fitted_params[:, 0]),\n",
    "            \"asy_mu\": 0.5*np.diff(np.mean(intervals, axis=0)[0])[0],\n",
    "            \"var\": np.mean(fitted_params[:, 1]),\n",
    "            \"sigma_on_var\": np.std(fitted_params[:, 1]),\n",
    "            \"asy_var\": 0.5*np.diff(np.mean(intervals, axis=0)[1])[0]\n",
    "        },\n",
    "        \"diag_cov\": {\n",
    "            \"mu\": np.mean(fitted_params_diag[:, 0]),\n",
    "            \"sigma_on_mu\": np.std(fitted_params_diag[:, 0]),\n",
    "            \"asy_mu\": 0.5*np.diff(np.mean(intervals_diag, axis=0)[0])[0],\n",
    "            \"var\": np.mean(fitted_params_diag[:, 1]),\n",
    "            \"sigma_on_var\": np.std(fitted_params_diag[:, 1]),\n",
    "            \"asy_var\": 0.5*np.diff(np.mean(intervals_diag, axis=0)[1])[0]\n",
    "            \n",
    "        }\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
